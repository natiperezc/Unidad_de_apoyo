<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Productos on Estadística, modelación y manejo de datos</title>
    <link>/recursos/</link>
    <description>Recent content in Productos on Estadística, modelación y manejo de datos</description>
    <generator>Source Themes academia (https://sourcethemes.com/academic/)</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 27 Jan 2020 00:00:00 +0000</lastBuildDate>
    
	    <atom:link href="/recursos/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Ajuste de modelos lineales</title>
      <link>/recursos/ajuste-modelos-lineales/</link>
      <pubDate>Mon, 27 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>/recursos/ajuste-modelos-lineales/</guid>
      <description>&lt;pre&gt;&lt;code class=&#34;language-{r&#34; data-lang=&#34;{r&#34;&gt;knitr::opts_chunk$set(echo = TRUE, fig.width=6, fig.height=4.5)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Como se mencionó en la sección anterior, la tabla de datos de emisiones de CO&lt;!-- raw HTML omitted --&gt;2&lt;!-- raw HTML omitted --&gt; fue ensamblada con el fin de establecer cuál es la importancia relativa del tamaño de la población y de la economía en la generación de emisiones de CO&lt;!-- raw HTML omitted --&gt;2&lt;!-- raw HTML omitted --&gt;. Esta pregunta parte de las premisas de que ambas variables constituyen una causalidad de las emisiones: se espera que la cantidad de CO&lt;!-- raw HTML omitted --&gt;2&lt;!-- raw HTML omitted --&gt; emitida por un país se incremente a medida que crece su población (posiblemente bajo el argumento de que personas adicionales implican el uso de recursos adicionales) y a medida que crece el tamaño de la actividad económica (a mayor actividad de producción, mayor cantidad de procesos que generan emisiones). La **Figura 1 ** sugiere una  asociación entre las emisiones de CO&lt;!-- raw HTML omitted --&gt;2&lt;!-- raw HTML omitted --&gt; y la población, en concordancia con una de las premisas del ejercicio. ¿Podemos sintetizar esta relación empleando un modelo estadístico? Por su puesto que sí. De hecho, existen diferentes tipos de modelos estadísticos para resumir esta relación. En la presente sesión haremos uso de una estrategia (herramienta) de modelación muy común: &lt;strong&gt;la regresión lineal simple&lt;/strong&gt;, la cual constituye un caso particular de los &lt;strong&gt;modelos lineales generales&lt;/strong&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{r&#34; data-lang=&#34;{r&#34;&gt;library(tidyverse)

emi &amp;lt;- read.csv(&amp;quot;CO2 2014.csv&amp;quot;, na.strings = &amp;quot;&amp;quot;)

emi &amp;lt;- emi %&amp;gt;% mutate(logpop = log10(Population.millions),
                      logemi = log10(CO2.emissions.Tg),
                      loggdp = log10(GDP.million.US.dollar))

fexp &amp;lt;- ggplot(emi, aes(logpop, logemi)) +
  theme(panel.background = element_blank(), legend.position=&amp;quot;none&amp;quot;, axis.line = element_line(colour = &amp;quot;black&amp;quot;)) +
  labs(y = expression(&#39;Emisiones de CO&#39;[2] * &#39; (log Tg)&#39;), x = &amp;quot;Población (log millones)&amp;quot;)

fexp + 
  geom_point(col =&amp;quot;blue&amp;quot;, alpha=0.75) +
  geom_line(stat=&amp;quot;smooth&amp;quot;, method=&amp;quot;lm&amp;quot;, se=FALSE, col =&amp;quot;blue&amp;quot;, size=1)
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&#34;recordando-la-línea-recta&#34;&gt;Recordando la línea recta&lt;/h1&gt;
&lt;p&gt;Cualquier línea recta puede describirse a través de la siguiente función matemática:&lt;/p&gt;
&lt;p&gt;$$
\begin{aligned}
y = f(x) = \beta_{0} + \beta_{1}x
\end{aligned}
$$&lt;/p&gt;
&lt;p&gt;En esta fórmula, la variable $y$ está en función de la variable $x$ a través de dos parámetros: el &lt;strong&gt;intercepto&lt;/strong&gt; ($\beta_{0}$) y la **pendiente** ($\beta_{1}$). El intercepto establece cuál es el valor de la variable $y$ cuando $x = 0$. Por su parte, la pendiente establece en cuántas unidades se incrementa el valor de Y por cada unidad de incremento en la variable X. Dependiendo del valor específico que tomen estos parámetros, la línea recta se trazará en una posición y/o con una inclinación diferente, como se ilustra en la **Figura 2**.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{r&#34; data-lang=&#34;{r&#34;&gt;library(ggpubr)

df1 &amp;lt;- data.frame(ymin1=c(-0.2899, 0.4101, 1.1101), xmin1=rep(0,3), ymax1=c(-0.2899, 0.4101, 1.1101), xmax1=rep(-2.25,3))

fexp.intercepts &amp;lt;- ggplot(emi, aes(logpop, logemi)) +
  geom_point(color=&amp;quot;white&amp;quot;) +
  theme(panel.background = element_blank(), legend.position=&amp;quot;none&amp;quot;, axis.line = element_line(colour = &amp;quot;black&amp;quot;)) +
  labs(y = &amp;quot;y&amp;quot;, x = &amp;quot;x&amp;quot;) +
  scale_x_continuous(expand = c(0,0), limits=c(-2.25,3.3)) +
  scale_y_continuous(expand = c(0,0), limits=c(-2.3,4.3)) +
  geom_abline(slope = 0.8815, intercept = -0.2899, color=&amp;quot;darkolivegreen4&amp;quot;, size=1) +
  geom_abline(slope = 0.8815, intercept = 0.4101, color=&amp;quot;darkolivegreen3&amp;quot;, size=1) +
  geom_abline(slope = 0.8815, intercept = 1.1101, color=&amp;quot;darkolivegreen2&amp;quot;, size=1) +
  geom_vline(xintercept = 0, color=&amp;quot;grey50&amp;quot;, size=1, linetype=2) +
geom_segment(aes(x = xmin1, y = ymin1, xend = xmax1, yend = ymax1), data = df1, colour = &amp;quot;grey50&amp;quot;, linetype=2)

df2 &amp;lt;- data.frame(ymin1=0.4101, xmin1=0, ymax1=0.4101, xmax1=-2.25)

fexp.slopes &amp;lt;- ggplot() +
  theme(panel.background = element_blank(), legend.position=&amp;quot;none&amp;quot;, axis.line = element_line(colour = &amp;quot;black&amp;quot;)) +
  labs(y = &amp;quot;y&amp;quot;, x = &amp;quot;x&amp;quot;) +
  scale_x_continuous(expand = c(0,0), limits=c(-2.25,3.3)) +
  scale_y_continuous(expand = c(0,0), limits=c(-2.3,4.3)) +
  geom_abline(slope = 1.1815, intercept = 0.4101, color=&amp;quot;darkorange4&amp;quot;, size=1) +
  geom_abline(slope = 0.8815, intercept = 0.4101, color=&amp;quot;darkorange3&amp;quot;, size=1) +
  geom_abline(slope = 0.5815, intercept = 0.4101, color=&amp;quot;darkorange2&amp;quot;, size=1) +
  geom_vline(xintercept = 0, color=&amp;quot;grey50&amp;quot;, size=1, linetype=2) +
geom_segment(aes(x = xmin1, y = ymin1, xend = xmax1, yend = ymax1), data = df2, colour = &amp;quot;grey50&amp;quot;, linetype=2)

ggarrange(fexp.intercepts, fexp.slopes, 
          labels = c(&amp;quot;a)&amp;quot;, &amp;quot;b)&amp;quot;),
          ncol = 2, nrow = 1, align = &amp;quot;h&amp;quot;)

&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&#34;la-línea-recta-aplicada-a-respuestas-ruidosas-regresión-lineal&#34;&gt;La línea recta aplicada a &amp;ldquo;respuestas ruidosas&amp;rdquo;: Regresión lineal&lt;/h1&gt;
&lt;p&gt;La línea recta constituye un modelo completamente determinístico: cada valor de $x$ predice un único valor posible de $y$ (&lt;strong&gt;Figura 2&lt;/strong&gt;). Sin embargo, la mayoría de los datos reales no se comportan de esta forma: un mismo valor de $x$ puede estar asociado a uno o más valores de $y$, la mayoría de las veces claramente diferentes al valor de $y$ establecido por la línea recta. Tal es el caso de las emisiones de CO&lt;!-- raw HTML omitted --&gt;2&lt;!-- raw HTML omitted --&gt;: si bien las emisiones siguen un patrón claro respecto a la población, éstas pueden tomar valores contrastantes y/o muy alejados de los valores esperados a partir del valor de población correspondiente (&lt;strong&gt;Figura 1&lt;/strong&gt;). Esto se debe a que las emisiones responden no solo al valor de la población, sino de otros factores no considerados hasta el momento y cuya acción parece ser completamente azarosa (aleatoria).&lt;/p&gt;
&lt;p&gt;La &lt;strong&gt;regresión lineal simple&lt;/strong&gt; es un modelo estadístico que permite conocer el valor específico que toma una variable $y$ al incorporar tanto el componente determinístico (relación entre $x$ y $y$, ambas contínuas), como la variación aleatoria en torno a esta relación. El componente determinístico describe cuál sería el valor esperado de la variable $y$ para cada valor de la variable $x$. En otras palabras, este componente &amp;ldquo;idealiza&amp;rdquo; el comportamiento de $y$ en relación a $x$. Dicha idealización o valor esperado de la variable $y$ para cada valor de la variable $x$ se denota como $\hat{y}$, por lo que estrictamente el modelo de la línea recta debe re-escribirse como:&lt;/p&gt;
&lt;p&gt;$$
\begin{aligned}
\hat{y} = f(x) = \beta_{0} + \beta_{1}x
\end{aligned}
$$&lt;/p&gt;
&lt;p&gt;¿Cómo saber cuál línea es la que mejor representa la tendencia general de la relación? En el caso particular de nuestro ejemplo, ¿cuáles deben de ser los valores de los parámetros para obtener la mejor idealización posible de la relación entre emisiones y población? Existen diferentes métodos matemáticos para establecer cuáles deben ser los valores de los parámetros para obtener el modelo más adecuado, de los cuales los más comunes son el método de mínimos cuadrados y el de máxima verosimilitud (ver Capítulo 6 en Bolker [-@Bolker2008]). Por ahora, basta con saber que las estimaciones de los parámetros de la línea recta en la &lt;strong&gt;Figura 1&lt;/strong&gt; son $\beta_{0} = 0.4101$ (intercepto) y $\beta_{1} = 0.8815$ (pendiente) y que el componente determinístico del modelo de regresión lineal puede ser escrito entonces como:&lt;/p&gt;
&lt;p&gt;$$
\begin{aligned}
\log_{10}(\hat{CO_{2}}) = 0.4101 + 0.8815* \log_{10}(pob)
\end{aligned}
$$&lt;/p&gt;
&lt;p&gt;Para convertir este modelo determinístico en uno probabilístico (y por ende estadístico), se requiere la inclusión de un término que represente la variación de las emisiones reales en torno a esta tendencia central o valor esperado. A ese término se le denomina &lt;strong&gt;error&lt;/strong&gt; o &lt;strong&gt;residuo&lt;/strong&gt; y no es más que la diferencia entre el valor real de $CO_{2}$ para cada observación y el valor *esperado* o *idealizado* de las emisiones ($\hat{CO_{2}}$) dado el valor de $x$:&lt;/p&gt;
&lt;p&gt;$$
\begin{aligned}
error_{i} = \log_{10}(CO_{2_{i}}) - \log_{10}(\hat{CO_{2_{i}}})  \ \ \ \ \ \ \ \ i: 1 \dots n
\end{aligned}
$$&lt;/p&gt;
&lt;p&gt;El subíndice $i$ indica la observación particular a la cual se hace referencia y por ende varía entre 1 (la primera observación) y $n$ (la última observación). Remplazando el valor de $\hat{CO_{2_{i}}}$ de la Eq.1 en la Eq. 2 y despejando para $CO_{2_{i}}$ se obtiene :&lt;/p&gt;
&lt;p&gt;$$
\begin{aligned}
\log_{10}(CO_{2_{i}}) &amp;amp;= 0.4101 + 0.8815*\log_{10}(pob_{i})\ + \ error_{i}
\end{aligned}
$$&lt;/p&gt;
&lt;p&gt;Ésta es la expresión del modelo de regresión lineal aplicado a la relación entre las emisiones de CO&lt;!-- raw HTML omitted --&gt;2&lt;!-- raw HTML omitted --&gt; y la población. Esta expresión permite obtener con precisión el valor de emisiones de $CO_{2_{i}}$ de un país cualquiera en la tabla de datos a partir de su valor de población (ambas en escala logarítmica de base 10) y de su error particular. El *error* corresponde a la porción aleatoria, es decir, aquella porción del valor de $CO_{2}$ que no es explicable o predecible por el tamaño de la población. Podrían existir países que tengan exactamente la misma población pero no las mismas emisiones de CO&lt;!-- raw HTML omitted --&gt;2&lt;!-- raw HTML omitted --&gt;. La razón para dicha variación es hasta este momento desconocida, y por ende, se entiende que su valor es resultado únicamente del azar.&lt;/p&gt;
&lt;p&gt;Veamos la representación gráfica de esta expresión (&lt;strong&gt;Figura 3&lt;/strong&gt;). En este caso, se resalta el dato correspondiente a los Estados Unidos de América, cuyo número de registro en la tabla de datos es el 201. El punto rojo con relleno azul claro indica el valor observado de emisiones ($CO_{2_{201}} = 3.72$, ver la tabla de datos *emi*). El punto rojo relleno corresponde al valor &amp;ldquo;idealizado&amp;rdquo;, es decir, el valor predicho al remplazar el valor de población en la Eq.1. ($\hat{CO_{2_{201}}} = 2.62$).&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{r&#34; data-lang=&#34;{r&#34;&gt;
lmexp &amp;lt;- lm(logemi ~ logpop, data = emi, na.action = na.exclude)
emi &amp;lt;- emi %&amp;gt;% mutate(pred.lmexp = predict(lmexp),
                      resid.lmexp = residuals(lmexp))

selobs &amp;lt;- c(201)
emisel &amp;lt;- slice(emi, selobs)

fexp +
  scale_x_continuous(expand = c(0,0), limits=c(-2.1,3.2), breaks=round(c(-2,-1,0,1,2,emisel$logpop, 3), digits=2)) +
  scale_y_continuous(expand = c(0,0), limits=c(-2.2,4.2), breaks=round(c(-2,0,2,emisel$pred.lmexp, emisel$logemi,4), digits=2)) +
  geom_point(col =&amp;quot;blue&amp;quot;, alpha=0.25, size=3) + 
  geom_line(stat=&amp;quot;smooth&amp;quot;, method=&amp;quot;lm&amp;quot;, se=FALSE, col =&amp;quot;blue&amp;quot;, alpha = 0.25, size=1) +
  geom_point(data=emisel, aes(logpop, logemi), col=&amp;quot;red&amp;quot;, shape=1, size=3) +
  geom_point(data=emisel, aes(logpop, pred.lmexp), col=&amp;quot;red&amp;quot;, alpha=0.75, size=3) +
  geom_segment(data=emisel, aes(x = logpop, y = logemi, xend = logpop, yend = pred.lmexp, col = &amp;quot;red&amp;quot;)) +
  annotate(geom = &amp;quot;text&amp;quot;, x=emisel$logpop, y=emisel$logemi, label=&amp;quot;CO[2[201]]&amp;quot;, parse=TRUE, hjust=&amp;quot;outward&amp;quot;, vjust=&amp;quot;outward&amp;quot;) +
  annotate(geom = &amp;quot;text&amp;quot;, x=emisel$logpop, y=emisel$pred.lmexp, label=&amp;quot;hat(CO)[2[201]]&amp;quot;, parse=TRUE, hjust=&amp;quot;outward&amp;quot;, vjust=&amp;quot;inward&amp;quot;) +
  geom_segment(aes(x = emisel$logpop, y = emisel$logemi, xend = -2.1, yend = emisel$logemi), colour = &amp;quot;grey50&amp;quot;, linetype=2) +
  geom_segment(aes(x = emisel$logpop, y = emisel$pred.lmexp, xend = -2.1, yend = emisel$pred.lmexp), colour = &amp;quot;grey50&amp;quot;, linetype=2) +
  geom_segment(aes(x = emisel$logpop, y = emisel$pred.lmexp, xend = emisel$logpop, yend = -2.1), colour = &amp;quot;grey50&amp;quot;, linetype=2)

&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;La población de los Estados Unidos de América (en escala log10) es de 2.50. Empleando la Eq. 2 podemos calcular el valor &lt;em&gt;predicho&lt;/em&gt; o &lt;em&gt;esperado&lt;/em&gt; de emisiones de $CO_{2}$ para un país con dicha población:&lt;/p&gt;
&lt;p&gt;$$
\begin{aligned}
\log_{10}(\hat{CO_{2_{201}}}) &amp;amp;= 0.4101 + 0.8815 * 2.50 \&lt;br&gt;
\log_{10}(\hat{CO_{2_{201}}}) &amp;amp;= 2.62
\end{aligned}
$$&lt;/p&gt;
&lt;p&gt;Las emisiones reales de Estados Unidos de América son superiores al valor esperado a partir del tamaño de su población. Las razones por las cuales esto ocurre son hasta ahora desconocidas. La diferencia entre estos dos valores está indicada por la línea roja en la &lt;strong&gt;Figura 3&lt;/strong&gt;, y su valor (&lt;em&gt;error&lt;/em&gt;) está dado por:&lt;/p&gt;
&lt;p&gt;$$
\begin{aligned}
error_{201} &amp;amp;= 3.72 - 2.62\&lt;br&gt;
error_{201} &amp;amp;= 1.10
\end{aligned}
$$&lt;/p&gt;
&lt;p&gt;La Eq. 4. expresada para los Estados Unidos de América corresponde a:&lt;/p&gt;
&lt;p&gt;$$
\begin{aligned}
3.72 &amp;amp;= 0.4101 + 0.8815 * 2.50 + 1.10
\end{aligned}
$$&lt;/p&gt;
&lt;h1 id=&#34;el-modelo-lineal-general&#34;&gt;El modelo lineal general&lt;/h1&gt;
&lt;p&gt;El modelo de la Eq.4 puede ser generalizado para el caso de cualquier variable respuesta aleatoria Y y cualquier predictor x:&lt;/p&gt;
&lt;p&gt;$$
\begin{aligned}
y_{i} = \beta_{0} + \beta_{1}x_{i} + \ \epsilon_{i}
\end{aligned}
$$&lt;/p&gt;
&lt;p&gt;A este modelo se le conoce como &lt;strong&gt;modelo lineal general&lt;/strong&gt;. El modelo es lineal no porque la relación se describa usando una línea recta, sino porque la variable $y$ es una función lineal de los parámetros del modelo $\beta_{0},\beta_{1}$. Dicho de forma más simple, las parámetros aparecen como múltiplos en cada término. Los modelos lineales pueden incluir relaciones no lineales, como en el caso de un polinomio de segundo orden.&lt;/p&gt;
&lt;p&gt;$$
\begin{aligned}
y_{i} = \beta_{0} + \beta_{1}x^{2}_{i} + \ \epsilon_{i}
\end{aligned}
$$&lt;/p&gt;
&lt;p&gt;En este caso la variable $y$ se incrementa de manera no lineal respecto a $x$. Sin embargo, el modelo es lineal en la medida en que sus parámetros $\beta_{0},\beta_{1}$ aparecen como múltiplos en sus términos correspondientes. Por el contrario, el modelo&lt;/p&gt;
&lt;p&gt;$$
\begin{aligned}
y_{i} = \beta_{1}x^{\beta_{2}}_{i} + \ \epsilon_{i}
\end{aligned}
$$&lt;/p&gt;
&lt;p&gt;no es un modelo lineal, pues $\beta_{2}$ aparece como potencia de $x$ y no como múltiplo de ésta.&lt;/p&gt;
&lt;p&gt;Los modelos lineales generales tienen una serie de supuestos fundamentales:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Los valores $y_{i}$ son independientes entre sí.&lt;/li&gt;
&lt;li&gt;$\epsilon$ es una variable aleatoria con distribución normal con media cero.&lt;/li&gt;
&lt;li&gt;La varianza de $\epsilon$ es constante a través de los valores predichos $\hat{y}$.&lt;/li&gt;
&lt;li&gt;la variable $x$ se mide sin error.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Todos estos supuestos surgen del método empleado para la estimación de los parámetros del modelo y por ende, para que dichas estimaciones sean válidas (y en particular su error estándar asociado), se requiere que los supuestos se cumplan.&lt;/p&gt;
&lt;h1 id=&#34;ajuste-del-modelo-lineal-en-r&#34;&gt;Ajuste del modelo lineal en R&lt;/h1&gt;
&lt;p&gt;Se le denomina &lt;strong&gt;ajuste&lt;/strong&gt; al proceso de estimación de los parámetros de un modelo estadístico cuando éste se aplica a un conjunto de datos específico. El proceso parte de que la formulación del modelo describe de manera adecuada la relación que se quiere modelar. En el caso de los datos de emisiones, vimos previamente que la asociación entre emisiones y población (ambos en escala logarítmica de base 10) puede modelarse adecuadamente empleando una línea recta (&lt;strong&gt;Figura 1&lt;/strong&gt;). Ajustaremos entonces el modelo lineal general definido en la Eq. 4 para modelar la relación entre estas dos variables. La función más ampliamente utilizada para ajustar modelos lineales generales en R es &lt;code&gt;lm&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{r&#34; data-lang=&#34;{r&#34;&gt;lm(log10(CO2.emissions.Tg) ~ log10(Population.millions), data = emi)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;La función se emplea usando el operador &lt;code&gt;~&lt;/code&gt;, que se lee &amp;ldquo;en función de&amp;rdquo;. A la izquierda del operador se coloca la variable respuesta y a la derecha la variable predictora (o variables predictoras, como veremos más adelante). El argumento &lt;em&gt;data&lt;/em&gt; sirve para especificar donde se encuentran almacenadas las variables. El llamado de la función genera la estimación de los parámetros del modelo, llamados &lt;em&gt;Coefficients&lt;/em&gt;. El primer parámetro, llamado &lt;em&gt;Intercept&lt;/em&gt;, corresponde a la estimación de $\beta_{0}$, es decir, el intercepto de la regresión lineal. El segundo parámetro, llamado *log10(Population.millions)*, corresponde a la estimación de $\beta_{1}$, que es la pendiente de la relación entre emisiones y población. El nombre se debe a que ese parámetro define el efecto de la población sobre la variable respuesta. Con estos valores se definió la línea de regresión de la **Figura 1**.&lt;/p&gt;
&lt;p&gt;Existen una serie de funciones adicionales que permiten obtener más información sobre el modelo ajustado. Para ello es conveniente guardar el ajuste del modelo en un objeto.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{r&#34; data-lang=&#34;{r&#34;&gt;mod1 &amp;lt;- lm(log10(CO2.emissions.Tg) ~ log10(Population.millions), data = emi)
summary(mod1)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;La función &lt;code&gt;summary&lt;/code&gt; sirve para obtener un resumen ampliado del ajuste del modelo: 1) genera la fórmula empleada en el ajuste; 2) un resumen de los errores (&lt;em&gt;Residuals&lt;/em&gt;) del modelo ; 3) un cuadro con estadísticas relacionadas a los parámetros del modelo (&lt;em&gt;Coefficients&lt;/em&gt;), donde se observa de nuevo su estimación en la columna &lt;em&gt;Estimate&lt;/em&gt;, el error estándar asociado a cada estimación (&lt;em&gt;Std.Error&lt;/em&gt;) y valores del estadístico t (&lt;em&gt;t value&lt;/em&gt;) y su probabilidad asociada (&lt;em&gt;Pr(&amp;gt;|t|)&lt;/em&gt;); y 4) una serie de estadísticas adicionales del modelo, tales como el coeficiente de determinación R&lt;!-- raw HTML omitted --&gt;2&lt;!-- raw HTML omitted --&gt; y el estadístico &lt;em&gt;F&lt;/em&gt; y valor de &lt;em&gt;p&lt;/em&gt; asociado a la prueba de hipótesis del modelo completo.&lt;/p&gt;
&lt;p&gt;Es posible extraer los valores estimados de los parámetros, los valores de emisión predichos por el modelo para cada país con base en su población ($\hat{CO_{2_{i}}}$), o el error asociado a cada país ($\epsilon_{i}$).&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{r&#34; data-lang=&#34;{r&#34;&gt;# Para extraer la estimación de los parámetros
coefficients(mod1)
# Para extraer las predicciones del modelo
predict(mod1)
# Para extraer los residuos del modelo
residuals(mod1)
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&#34;validación-del-ajuste-del-modelo-lineal&#34;&gt;Validación del ajuste del modelo lineal&lt;/h1&gt;
&lt;p&gt;Como se mencionó previamente, todo modelo lineal tiene cuatro supuestos básicos: 1) independencia de datos, 2) normalidad de errores, 3) homogeneidad de varianza de los errores (homocedasticidad), y 4) variable independiente medida sin error. La función &lt;code&gt;plot&lt;/code&gt; aplicada al modelo lineal genera cuatro gráficos que, además ayudar a comprobar el cumplimiento de los supuestos 2 y 3, permite diagnosticar otro tipo de situaciones relacionadas con el ajuste del modelo, tales como la idoneidad del modelo empleado (que la forma que describe es adecuada para el patrón de relación entre las variables) o la presencia de datos muy influyentes en el ajuste del modelo.&lt;/p&gt;
&lt;p&gt;```{r Figura 4, fig.height=8, fig.width=10, fig.cap = &amp;ldquo;&lt;strong&gt;Figura 4.&lt;/strong&gt; Gráficos diagnósticos del modelo lineal obtenidos usando la función &lt;code&gt;plot&lt;/code&gt;.&amp;quot;}
par(mfrow=c(2,2))
plot(mod1, col=&amp;quot;blue&amp;rdquo;, pch=21)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
En la **Figura 4**, el gráfico en la esquina superior izquierda se denomina comúnmente **gráfico de residuos** o **gráfico de errores** y sirve para diagnosticar la homogeneidad de varianza, así como la ideneidad del modelo ajustado para describir la forma de la relación entre las variables. En él los valores predichos por el modelo ($\hat{CO_{2}}$) aparecen en el eje horizontal y los errores correspondientes ($\epsilon$) en el vertical. El gráfico a su derecha se denomina **gráfico Q-Q** y sirve principalmente para diagnosticar si los errores siguen la distribución de probabilidades esperada (en este caso, normal). En éste se emplean los residuos estandarizados, es decir, divididos por la desviación estándar. El gráfico inferior izquierdo es un **scale-location plot**, que muestra la raiz cuadrada del valor absoluto de los residuos estandarizados en el eje vertical y los valores predichos en el horizontal. Este gráfico también permite diagnosticar la homogeneidad de varianza. Por último, el gráfico inferior derecho es un gráfico de **residuos contra leverage**. El leverage (algunas veces traducido como **apalancamiento**) se refiere a la distancia de un dato respecto al resto de datos en el eje de la variable predictora. Un dato en el eje predictor que se encuentra muy alejado de los demás puede llegar a influir de forma importante el resultado del ajuste. Por ello, esta gráfica ayuda a detectar datos altamente influyentes.

¿Qué se debería ver en estos gráficos? Para darse una idea, en la **Figura 5** se presentan los mismos gráficos diagnósticos pero para diferentes situaciones particulares. En el escenario ideal la relación entre un par de variables $x$ y $y$ es adecuadamente descrita por la línea recta asociada al modelo lineal empleado hasta el momento (gráfica superior de la columna *Ideal*); . adicionalmente, los errores o residuos del modelo siguen una distribución normal con varianza homogénea. En este caso, la distribución de los residuos respecto a los valores predichos por el modelo (segunda línea de la primera columna) es homogénea a lo largo del rango de valores predichos, el gráfico-qq muestra los puntos dispuestos a lo largo de una línea recta punteada, y la gráfica de residuos contra leverage no señala ninguna tendencia en los residuos ni alguna observación cuyo valor de distancia de Cook sea cercano a 0.5. este es, como su nombre lo dice, el escenario ideal.

```{r Figura 5, echo =FALSE, eval = TRUE, message=FALSE, fig.width=16, fig.height=14, fig.cap = &amp;quot;**Figura 5.** Gráficos diagnósticos para datos con características particulares. La columna *Ideal* corresponde a una relación entre variables x-y que cumple los supuestos de normalidad y homocedasticidad de los errores, y para la que el modelo lineal describe adecuadamente la relación. La columna *Heterocedasticidad* presenta una situación con errores heterocedásticos, cuya varianza se incrementa con el valor de x. En *No linealidad* se presenta el caso de una relación en la que las variables x y y presentan una asociación no lineal. Por último, en la columna de *Datos extremos* se presenta un caso en el que dos de los datos incluidos presentan valores extremos de la variable y.&amp;quot;}

library(ggpubr)

set.seed(1234321)
xaleat &amp;lt;- runif(n=100, min=0, max=10) # Generamos valores del predictor x aleatoriamente distribuidos en el rango de 0 a 10
y1 &amp;lt;- 0.4 + 10*xaleat + rnorm(100, mean = 0, sd = 10) # La variable dependiente y1 se relaciona linealmente con xaleat, y presenta un error con distribución normal y desviación estándar (i.e. varianza) homogénea.
y2 &amp;lt;- 0.4 + 10*xaleat + rnorm(100, mean = 0, sd = xaleat) # La variable dependiente y2 se relaciona linealmente con xaleat, pero la varianza del arror se incrementa con el promedio de y2
y3 &amp;lt;- 10 + xaleat^2 + rnorm(100, mean = 0, sd = 10) # La variable y3 depende no linealmente de xaleat, varianza homogenea
y4 &amp;lt;- c(-10,0.4 + 10*xaleat[2:99] + rnorm(98, mean = 0, sd = 10), 120) # La variable x4 se relaciona linealmente con xaleat, la varianza es homogénea pero hay dos datos extremos
dat &amp;lt;- data.frame(xaleat,y1, y2, y3,y4)


lm1 &amp;lt;- lm(y1~xaleat, data =dat)

xy1.gr &amp;lt;- ggplot(dat, aes(y=y1, x=xaleat)) + 
  theme(panel.background = element_blank(), axis.line = element_line(colour = &amp;quot;black&amp;quot;)) +
  labs(x=&amp;quot;x&amp;quot;, y=&amp;quot;y&amp;quot;) +
  geom_point(alpha=0.35, color=&amp;quot;green4&amp;quot;, size=3) +
  geom_smooth(method=&amp;quot;lm&amp;quot;, se=FALSE)

res1.gr &amp;lt;- ggplot(lm1, aes(.fitted, .resid)) + 
  theme(panel.background = element_blank(), axis.line = element_line(colour = &amp;quot;black&amp;quot;)) +
  labs(x=&amp;quot;Fitted values&amp;quot;, y=&amp;quot;Residuals&amp;quot;) +
  geom_point(alpha=0.35, color=&amp;quot;green4&amp;quot;, size=3) +
  geom_smooth(se=FALSE, color=&amp;quot;red&amp;quot;) +
  geom_hline(yintercept = 0, linetype=2)

qq1.gr &amp;lt;- ggplot(lm1, aes(sample=.stdresid)) + 
  stat_qq(alpha=0.35, color=&amp;quot;green4&amp;quot;, size=3) + 
  geom_abline(slope = 1, linetype=2) + 
  theme(panel.background = element_blank(), axis.line = element_line(colour = &amp;quot;black&amp;quot;)) +
  labs(x=&amp;quot;Theoretical quantiles&amp;quot;, y=&amp;quot;Standardized residuals&amp;quot;)

rl1.gr &amp;lt;- ggplot(lm1, aes(.hat, .stdresid)) +
  geom_point(aes(size = .cooksd),alpha=0.35, color=&amp;quot;green4&amp;quot;) +
  geom_smooth(se = FALSE, color=&amp;quot;red&amp;quot;) +
  theme(panel.background = element_blank(), axis.line = element_line(colour = &amp;quot;black&amp;quot;)) + 
  labs(x=&amp;quot;Leverage&amp;quot;, y=&amp;quot;Standardized residuals&amp;quot;, size=&amp;quot;Cook&#39;s \ndistance&amp;quot;) 

lm2 &amp;lt;- lm(y2~xaleat, data =dat)

xy2.gr &amp;lt;- ggplot(dat, aes(y=y2, x=xaleat)) + 
  theme(panel.background = element_blank(), axis.line = element_line(colour = &amp;quot;black&amp;quot;)) +
  labs(x=&amp;quot;x&amp;quot;, y=&amp;quot;y&amp;quot;) +
  geom_point(alpha=0.35, color=&amp;quot;yellow3&amp;quot;, size=3) +
  geom_smooth(method=&amp;quot;lm&amp;quot;, se=FALSE)

res2.gr &amp;lt;- ggplot(lm2, aes(.fitted, .resid)) + 
  theme(panel.background = element_blank(), axis.line = element_line(colour = &amp;quot;black&amp;quot;)) +
  labs(x=&amp;quot;Fitted values&amp;quot;, y=&amp;quot;Residuals&amp;quot;) +
  geom_point(alpha=0.35, color=&amp;quot;yellow3&amp;quot;, size=3) +
  geom_smooth(se=FALSE, color=&amp;quot;red&amp;quot;) +
  geom_hline(yintercept = 0, linetype=2)

qq2.gr &amp;lt;- ggplot(lm2, aes(sample=.stdresid)) + 
  stat_qq(alpha=0.35, color=&amp;quot;yellow3&amp;quot;, size=3) + 
  geom_abline(slope = 1, linetype=2) + 
  theme(panel.background = element_blank(), axis.line = element_line(colour = &amp;quot;black&amp;quot;)) +
  labs(x=&amp;quot;Theoretical quantiles&amp;quot;, y=&amp;quot;Standardized residuals&amp;quot;)

rl2.gr &amp;lt;- ggplot(lm2, aes(.hat, .stdresid)) +
  geom_point(aes(size = .cooksd),alpha=0.35, color=&amp;quot;yellow3&amp;quot;) +
  geom_smooth(se = FALSE, color=&amp;quot;red&amp;quot;) +
  theme(panel.background = element_blank(), axis.line = element_line(colour = &amp;quot;black&amp;quot;)) + 
  labs(x=&amp;quot;Leverage&amp;quot;, y=&amp;quot;Standardized residuals&amp;quot;, size=&amp;quot;Cook&#39;s \ndistance&amp;quot;)

lm3 &amp;lt;- lm(y3~xaleat, data =dat)

xy3.gr &amp;lt;- ggplot(dat, aes(y=y3, x=xaleat)) + 
  theme(panel.background = element_blank(), axis.line = element_line(colour = &amp;quot;black&amp;quot;)) +
  labs(x=&amp;quot;x&amp;quot;, y=&amp;quot;y&amp;quot;) +
  geom_point(alpha=0.35, color=&amp;quot;orange3&amp;quot;, size=3) +
  geom_smooth(method=&amp;quot;lm&amp;quot;, se=FALSE)

res3.gr &amp;lt;- ggplot(lm3, aes(.fitted, .resid)) + 
  theme(panel.background = element_blank(), axis.line = element_line(colour = &amp;quot;black&amp;quot;)) +
  labs(x=&amp;quot;Fitted values&amp;quot;, y=&amp;quot;Residuals&amp;quot;) +
  geom_point(alpha=0.35, color=&amp;quot;orange3&amp;quot;, size=3) +
  geom_smooth(se=FALSE, color=&amp;quot;red&amp;quot;) +
  geom_hline(yintercept = 0, linetype=2)

qq3.gr &amp;lt;- ggplot(lm3, aes(sample=.stdresid)) + 
  stat_qq(alpha=0.35, color=&amp;quot;orange3&amp;quot;, size=3) + 
  geom_abline(slope = 1, linetype=2) + 
  theme(panel.background = element_blank(), axis.line = element_line(colour = &amp;quot;black&amp;quot;)) +
  labs(x=&amp;quot;Theoretical quantiles&amp;quot;, y=&amp;quot;Standardized residuals&amp;quot;)

rl3.gr &amp;lt;- ggplot(lm3, aes(.hat, .stdresid)) +
  geom_point(aes(size = .cooksd),alpha=0.35, color=&amp;quot;orange3&amp;quot;) +
  geom_smooth(se = FALSE, color=&amp;quot;red&amp;quot;) +
  theme(panel.background = element_blank(), axis.line = element_line(colour = &amp;quot;black&amp;quot;)) + 
  labs(x=&amp;quot;Leverage&amp;quot;, y=&amp;quot;Standardized residuals&amp;quot;, size=&amp;quot;Cook&#39;s \ndistance&amp;quot;)

lm4 &amp;lt;- lm(y4~xaleat, data =dat)

xy4.gr &amp;lt;- ggplot(dat, aes(y=y4, x=xaleat)) + 
  theme(panel.background = element_blank(), axis.line = element_line(colour = &amp;quot;black&amp;quot;)) +
  labs(x=&amp;quot;x&amp;quot;, y=&amp;quot;y&amp;quot;) +
  geom_point(alpha=0.35, color=&amp;quot;red4&amp;quot;, size=3) +
  geom_smooth(method=&amp;quot;lm&amp;quot;, se=FALSE)

res4.gr &amp;lt;- ggplot(lm4, aes(.fitted, .resid)) + 
  theme(panel.background = element_blank(), axis.line = element_line(colour = &amp;quot;black&amp;quot;)) +
  labs(x=&amp;quot;Fitted values&amp;quot;, y=&amp;quot;Residuals&amp;quot;) +
  geom_point(alpha=0.35, color=&amp;quot;red4&amp;quot;, size=3) +
  geom_smooth(se=FALSE, color=&amp;quot;red&amp;quot;) +
  geom_hline(yintercept = 0, linetype=2)

qq4.gr &amp;lt;- ggplot(lm4, aes(sample=.stdresid)) + 
  stat_qq(alpha=0.35, color=&amp;quot;red4&amp;quot;, size=3) + 
  geom_abline(slope = 1, linetype=2) + 
  theme(panel.background = element_blank(), axis.line = element_line(colour = &amp;quot;black&amp;quot;)) +
  labs(x=&amp;quot;Theoretical quantiles&amp;quot;, y=&amp;quot;Standardized residuals&amp;quot;)

rl4.gr &amp;lt;- ggplot(lm4, aes(.hat, .stdresid)) +
  geom_point(aes(size = .cooksd),alpha=0.35, color=&amp;quot;red4&amp;quot;) +
  geom_smooth(se = FALSE, color=&amp;quot;red&amp;quot;) +
  theme(panel.background = element_blank(), axis.line = element_line(colour = &amp;quot;black&amp;quot;)) + 
  labs(x=&amp;quot;Leverage&amp;quot;, y=&amp;quot;Standardized residuals&amp;quot;, size=&amp;quot;Cook&#39;s \ndistance&amp;quot;)

fig5 &amp;lt;- ggarrange(xy1.gr, xy2.gr+rremove(&amp;quot;ylab&amp;quot;), xy3.gr+rremove(&amp;quot;ylab&amp;quot;), xy4.gr+rremove(&amp;quot;ylab&amp;quot;),
          res1.gr, res2.gr+rremove(&amp;quot;ylab&amp;quot;), res3.gr+rremove(&amp;quot;ylab&amp;quot;), res4.gr+rremove(&amp;quot;ylab&amp;quot;), 
          qq1.gr,  qq2.gr+rremove(&amp;quot;ylab&amp;quot;),  qq3.gr+rremove(&amp;quot;ylab&amp;quot;),  qq4.gr+rremove(&amp;quot;ylab&amp;quot;),  
          rl1.gr, rl2.gr+rremove(&amp;quot;ylab&amp;quot;), rl3.gr+rremove(&amp;quot;ylab&amp;quot;), rl4.gr+rremove(&amp;quot;ylab&amp;quot;),
          ncol = 4, nrow = 4)

annotate_figure(fig5,
                top = text_grob(&amp;quot;                  Ideal                      Heterocedasticidad                No linealidad                    Datos extremos    &amp;quot;, size=24))


&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Ahora veamos que pasa cuando la situación no es la ideal. En la columna &lt;em&gt;Heterocedasticdad&lt;/em&gt; de la &lt;strong&gt;Figura 5&lt;/strong&gt; se hace referencia a una situación en la cual los errores no presentan varianza homogénea, sino que por el contrario la varianza de los residuos se incrementa a medida que los valores predichos se incrementan (gráfico en la segunda línea). Asociado a ello, el gráfico&amp;ndash;qq muestra una desviación importante respecto a la línea recta punteada. Este patrón es bastante común al ajustar modelos lineales generales e implica una violación a uno de los supuestos fundamentales de éstos, la homocedaticidad. En estos casos, se requiere hacer alguna modificación durante la modelación, ya sea através de la transformación de la variable respuesta, o mediante la modelación de la varianza (veremos algunos casos de ello más adelante).&lt;/p&gt;
&lt;p&gt;Otra situación no ideal ocurre cuando el modelo lineal empleado no representa adecuadamente la relación entre las variables, como se muestra en el primer gráfico de la columna &lt;em&gt;Bo linealidad&lt;/em&gt; (&lt;strong&gt;Figura 5&lt;/strong&gt;). En este caso, la relación es claramente no lineal, tal vez de tipo polinomial de segundo orden (que puede ser modelada empleando un modelo lineal), de tipo exponencial, en cuyo caso existen modelos más adecuados (como veremos en los modelos lineales generalizados, o con modelos no lineales). El último caso de situación no-ideal presentado acá es el de la presencia de datos extremos, como se muestra en la última columna de la &lt;strong&gt;Figura 5&lt;/strong&gt;. En este ejemplo hay dos datos cuyo valor para la variable $y$ es muy alto o muy bajo dado su valor de $x$. En este caso, tanto el gráfico de residuos contra predicho como el gráfico qq muestran claramente que estos dos datos se salen de la masa central de datos. El gráfico de Leverage presenta claramente como la distancia de Cook para estos dos datos tiene valores cercanos o incluso superiores a 0.5, indicando que son datos altamente influyentes. En estos casos, es adecuado revisar la tabla de datos para ver si se trata de un error en la transcripción de la información. Si no lo es, hay que considerar si es adecuado o no remover dichos datos del análisis; aunque esta opción no es la ideal, el ajuste del modelo y las conclusiones que se sacan del mismo pueden depender drásticamente de su inclusión.  Si la decisión es excluirlos, se debe de reportar tal situación durante la presentación de los resultados del ajuste del modelo.&lt;/p&gt;
&lt;h1 id=&#34;inferencia-estadística-respecto-al-modelo&#34;&gt;Inferencia estadística respecto al modelo&lt;/h1&gt;
&lt;p&gt;Si el diagnóstico gráfico de los modelos es positivo, de tal forma que se considera que el modelo es adecuado y que se cumplen los supuestos del mismo, es adecuado proceder entonces a la inferencia estadística. La &lt;strong&gt;inferencia estadística&lt;/strong&gt; se refiere a la toma de decisión respecto al efecto hipotetizado de la(s) variable(s) predictoras sobre la respuesta. En términos estadísticos, la inferencia se refiere a llegar a conclusiones respecto a propiedades de una población (estadística) a partir de una muestra. Existen al menos tres aproximaciones diferentes a la inferencia estadística en la actualidad: 1) las pruebas de hipótesis basadas en estadística frecuentista, 2) la selección de modelos empleando criterios de información, y 3) la estadística bayesiana. En este curso abordaremos las dos primeras.&lt;/p&gt;
&lt;h2 id=&#34;pruebas-de-hipótesis&#34;&gt;Pruebas de hipótesis&lt;/h2&gt;
&lt;p&gt;Las pruebas de hipótesis consisten, en términos generales, en calcular la probabilidad asociada a observar un evento específico si se toma por cierta una hipótesis particular, que generalmente es la de no existencia de efecto o relación (hipótesis nula). Si dicha probabilidad calculada es baja (&amp;lt; 0.05), entonces se presume que es debido la hipótesis de partida no es cierta en realidad, por lo cual se rechaza dicha hipótesis nula y se toma como cierta la hipótesis alterna. En el caso de los modelos lineales existen dos tipos generales de pruebas de hipótesis. El primero corresponde a las pruebas sobre los parámetros específicos del modelo, las cuales se obtienen en la sección de coefficientes del resumen del modelo.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{r}&#34; data-lang=&#34;{r}&#34;&gt;coef(summary(mod1))
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;En estas pruebas de hipótesis se prueba si cada parámetro estimado es diferente de cero (hipótesis nula) empleando para ello el estadístico &lt;em&gt;t de Student&lt;/em&gt; (&lt;em&gt;t value&lt;/em&gt;) y su probabilidad asociada. (&lt;em&gt;Pr(&amp;gt;|t|)&lt;/em&gt;). A estas pruebas se les conoce como &lt;strong&gt;pruebas t de Wald&lt;/strong&gt;. La conclusión en este caso es que hay evidencia suficiente para rechaz&amp;lt;ar la hipótesis nula de que tanto el intercepto como la pensiente son diferentes de cero.&lt;/p&gt;
&lt;p&gt;El segundo tipo de prueba de hipótesis corresponde a la prueba del modelo en su conjunto: se prueba si la capacidad explicativa del modelo ajustado es superior a la de un modelo nulo que no posee variables predictoras y en la que por ende la variación en la respuesta es completamente debida al azar. El estadístico &lt;em&gt;F&lt;/em&gt; y su probabilidad &lt;em&gt;p&lt;/em&gt; asociada que se muestran en el resumen del modelo presenta corresponden a dicha prueba de hipótesis.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{r}&#34; data-lang=&#34;{r}&#34;&gt;# Extracción del estadístico F asociado al modelo completo y su valor de *p*
f &amp;lt;- summary(mod1)$fstatistic
f
pf(f[1],f[2],f[3], lower.tail = FALSE)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;La conclusicón es este caso es que el modelo tiene mayor capacidad explicativa de las emisiones de CO&lt;!-- raw HTML omitted --&gt;2&lt;!-- raw HTML omitted --&gt; que un modelo nulo que no tiene predictores. Es posible generar el mismo resultado si se ajusta el modelo nulo (sin predictores) y se comparan el modelo original y el nulo empelando la función &lt;code&gt;anova&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{r}&#34; data-lang=&#34;{r}&#34;&gt;#Ajuste del modelo nulo sin predictores
mod0 &amp;lt;- lm(log10(CO2.emissions.Tg) ~ 1, data = emi)

# Comparación de los modelos 
anova(mod1,mod0)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Nótese que el valor de F obtenido y su probabilidad asociada es el mismo en ambos casos. A este tipo de prueba se le conoce como &lt;strong&gt;prueba de razón de verosimilitud&lt;/strong&gt; y puede ser usada para contrastar dos o más &lt;strong&gt;modelos anidados&lt;/strong&gt;. Un modelo está anidado en otro cuando su conjunto de variables predictores es subconjunto de los predictores incluidos en el modelo más grande. En este caso, el modelo nulo está anidado en el modelo original, pues sus predictores (conjunto vacío), son un subconjunto de los predictores en el modelo original (población). Usaremos este tipo de prueba de manera recurrente más adelante para modelos más complejos.&lt;/p&gt;
&lt;h2 id=&#34;selección-de-modelos-basada-en-criterios-de-información&#34;&gt;Selección de modelos basada en criterios de información&lt;/h2&gt;
&lt;p&gt;Cuando tenemos un conjunto de explicaciones alternativas (hipótesis), representadas en diferentes modelos estadísticos, es necesario poder comparar el desempeño de dichos modelos en la recreación de la realidad (datos). Los criterios de información proveen estimaciones de la evidencia empírica relativa en favor de cada modelo, es decir, cuál de los modelos está, en términos relativos, mejor sustentado por los datos. El criterio de información más ampliamente utilizado es el de Akaike (&lt;strong&gt;AIC&lt;/strong&gt;), el cual está constuido a partir de dos términos, uno que mide qué tan bien el modelo reproduce la realidad y otro que mide la complejidad del modelo:&lt;/p&gt;
&lt;p&gt;$$
\begin{equation}
AIC = -2log(\mathcal{L}(\hat{\theta})|datos) + 2K
\end{equation}
$$&lt;/p&gt;
&lt;p&gt;El término $-2log(\mathcal{L}(\hat{\theta})|datos)$ es sencillamente el logaritmo del valor de la función de verosimilitud. Como lo vimos previamente, la verosimilitud es una medida relativa de la posibilidad de obtener un modelo con los parámetros especificados, dados los datos que tenemos a la mano. Un modelo que describa mejor un conjunto de datos tiene un valor más grande para la función de verosimilitud en relación a otros modelos, de tal forma que el término $-2log(\mathcal{L}(\hat{\theta})|datos)$ se hace más pequeño (más negativo) a medida que incrementamos la &lt;em&gt;calidad&lt;/em&gt; del modelo. Sin embargo, es conocido que entre más parametros tiene un modelo mejor se ajusta a los datos y por ende mayor es su valor de verosimilud. El término $2K$ adiciona 2 unidades por cada parámetro adicional en el modelo, &lt;em&gt;penalizando&lt;/em&gt; modelos cada vez más complejos. El valor de &lt;strong&gt;AIC&lt;/strong&gt; es entonces un indicador del ajuste relativo de los modelos al conjunto de datos, de tal forma que modelos con AIC más bajos (mayor valor de verosimilitud y menor número de parámetros) son considerados mejores en términos relativos [@Anderson2008].&lt;/p&gt;
&lt;p&gt;El criterio de Akaike puede ser calculado empleando la función &lt;code&gt;AIC&lt;/code&gt;. Sin embargo, en la práctica es muy común que el conjunto de datos analizado sea pequeño (por ejemplo, menos de 50 observaciones diferentes). Cuando la muestra es pequeña el valor de AIC tiene un sesgo que favorece a modelos con más parámetros, por lo que comúnmente se utiliza una formulación del AIC corregida para muestras pequeñas, &lt;strong&gt;AICc&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;$$
AIC = -2log(\mathcal{L}(\hat{\theta})|datos) + 2K\Big(\frac{n}{n-k-1}\Big)
$$&lt;/p&gt;
&lt;p&gt;El &lt;strong&gt;AICc&lt;/strong&gt; puede ser calculado empleando varias funciones en R. En adelante emplearemos la función &lt;code&gt;AICc&lt;/code&gt; de la librería &lt;code&gt;MuMIn&lt;/code&gt;. Veamos entonces cuáles son los valores de AIC para los modelos ajustados a los datos de emisiones de CO&lt;!-- raw HTML omitted --&gt;2&lt;!-- raw HTML omitted --&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{r&#34; data-lang=&#34;{r&#34;&gt;library(MuMIn)
AICc(mod0,mod1)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Claramente el valor de AICc para el modelo que incluye como predictor a la población es inferior al modelo nulo que no incluye predictores. En este caso, existe mucha más evidencia relativa en favor del modelo alternativo que del modelo nulo. Otra función útil para comparar dos o más modelos empleando el AIcc es la función &lt;code&gt;model.sel&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{r}&#34; data-lang=&#34;{r}&#34;&gt;model.sel(mod0,mod1)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Esta función despliega una tabla que presenta cada modelo incluido en una fila diferente y en cada columna información sobre los mismos. Se presentan los valores de los parámetros estimados (columnas &lt;em&gt;(Int)&lt;/em&gt; y &lt;em&gt;l10(Ppl.mll)&lt;/em&gt;), los grados de libertad asociados a cada modelo, su valor de verosimilitud &lt;em&gt;(logLik)&lt;/em&gt;, el valor del criterio de Akaike corregido para muestras pequeñas (&lt;em&gt;AICc&lt;/em&gt;), la diferencia en el valor de (&lt;em&gt;AICc&lt;/em&gt;) entre cada modelo y el modelo con el AICc más bajo (&lt;em&gt;delta&lt;/em&gt;) y el peso de evidencia relativo asociado a cada modelo (&lt;em&gt;weight&lt;/em&gt;). Estas dos últimas columnas son importantes para hacer la inferencia respecto a los modelos.&lt;/p&gt;
&lt;p&gt;El $\Delta AICc$ indica qué tanto apoyo tiene un modelo en relación al modelo con mayor evidencia a su favor. Entre más cercano sea este valor a cero, quiere decir que dicho modelo se parece mucho al mejor modelo y que existe poca evidencia que favorezca a uno de los dos en particular. Si bien se ha usado como regla práctica que cualquier modelo con $\Delta AIC &amp;gt; 2$ puede ser descartado como un modelo interesante o informativo, no existe en realidad un punto de corte para descartar modelos. La posibilidad de descartar un modelo debe ser evaluada a la luz de otros argumentos [@Anderson2008]. Por su parte, la columna de pesos de evidencia $w$ representa una medida de la probabilidad relativa de los modelos. El modelo con menor valor de AIC obtiene el valor más alto de $w$. Los valores de $w$ suman en total 1, por lo que proveen evidencia de la probabilidad relativa de cada modelo de representar el proceso que generó los datos.&lt;/p&gt;
&lt;h1 id=&#34;visualización-del-ajuste-del-modelo&#34;&gt;Visualización del ajuste del modelo&lt;/h1&gt;
&lt;p&gt;Una vez se ha tomado una decisión respecto a la pertinencia de un modelo para representar la relación entre las variables es ideal visualizar el ajuste del modelo, ya sea como parte del reporte de los resultados, o simplemente para confirmar que el modelo constituye una representación adecuada de los datos y así evaluar si es suficiente o si se requiere emplear otras aproximaciones para la modelación. En el caso de la regresión lineal simple, la visualización del ajuste es relativamente sencilla. En la sección anterior vimos como aplicando un &lt;code&gt;geom_smooth&lt;/code&gt; en una gráfica de &lt;code&gt;ggplot&lt;/code&gt; podemos obtener rápidamente una representación del modelo de regresión:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{r&#34; data-lang=&#34;{r&#34;&gt;ggplot(emi, aes(log10(Population.millions), log10(CO2.emissions.Tg))) + 
  geom_point() +
  geom_smooth(method = &amp;quot;lm&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;La opción &amp;ldquo;lm&amp;rdquo; en el argumento &lt;em&gt;method&lt;/em&gt; permite especificar que el modelo que se quiere representar es un modelo lineal, en este caso una regresión lineal simple. La línea azul representa la estimación derivada de la porción determinística del modelo, mientras que el área gris a su alrededor el intervalo de confianza del 95% para dicha estimación. Si bien esta opción es muy práctica, tiene restricciones en cuanto al tipo y detalles de los modelos que se pueden desplegar (ver la ayuda de la función, &lt;code&gt;?geom_smooth&lt;/code&gt;). Una forma más general de graficar el ajuste de un modelo es mediante la predicción de nuevos valores a partir del modelo empleando la función &lt;code&gt;predict&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{r&#34; data-lang=&#34;{r&#34;&gt;# Generación de una tabla de datos con nuevos valores de población y PIB
nuevos &amp;lt;- data.frame(Population.millions = seq(from = min(emi$Population.millions, na.rm = TRUE), to = max(emi$Population.millions, na.rm = TRUE), length.out = 1000),
                     GDP.million.US.dollar = seq(from = min(emi$GDP.million.US.dollar, na.rm = TRUE), to = max(emi$GDP.million.US.dollar, na.rm = TRUE), length.out = 1000))

# Generación de las estimaciones y su intervalo de confianza
predichos &amp;lt;- predict(mod1, newdata = nuevos, interval = c(&amp;quot;confidence&amp;quot;))

# Integración de las variables predictoras y los valores estimados en una tabla
emi.nue &amp;lt;- data.frame(nuevos, predichos)

# Generación de la gráfica
ggplot(emi, aes(log10(Population.millions), log10(CO2.emissions.Tg))) + 
  geom_point() +
  geom_line(data=emi.nue, aes(log10(Population.millions), fit), col=&amp;quot;blue3&amp;quot;, size=1) +
  geom_line(data=emi.nue, aes(log10(Population.millions), lwr), col=&amp;quot;blue1&amp;quot;, size=1, linetype=2) +
  geom_line(data=emi.nue, aes(log10(Population.millions), upr), col=&amp;quot;blue1&amp;quot;, size=1, linetype=2)
  
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Una última opción muy práctica, particularmente para modelos más complejos es la función &lt;code&gt;visreg&lt;/code&gt;en la biblioteca del mismo nombre:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{r&#34; data-lang=&#34;{r&#34;&gt;library(visreg)
visreg(mod1, xtrans = log)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;El uso del argumento &lt;em&gt;xtrans&lt;/em&gt; es necesario en este caso porque la función &lt;code&gt;visreg&lt;/code&gt; grafica por descarte el predictor en su escala original, no transformada.&lt;/p&gt;
&lt;h1 id=&#34;qué-reportar&#34;&gt;¿Qué reportar?&lt;/h1&gt;
&lt;p&gt;En el caso de un modelo de regresión lineal simple, posiblemente lo más sencillo es presentar una gráfica que muestre el ajuste del modelo y que incluya información adicional, como la ecuación del modelo y el valor del coeficiente de determinación $R^2$. Esto permite además evaluar la calidad del ajuste, al ver el comportamiento del modelo en relación ala nube de puntos. Si el objetivo es tan solo mencionar que existe el efecto (por ejemplo, cuando el análisis no es central en los resultados), se puede incluir directamente en el texto un resumen del procedimiento de inferencia (valores del estadístico de prueba y probabilidad asociados, o la probabilidad $w$ asociada al modelo si se empleó selección de modelos por criterios de información). En cualquier caso, siempre es altamente recomendable reportar si el modelo cumplió con los supuestos (en primera instancia sí, o de lo contrario sería un error reportarlo), o mejor aún, presentar como mqaterial suplementario dicha evidencia. Esto con el fin de mostrar que el ajuste del modelo es adecuado y que las inferencias que de él se derivan son correctas [@Zuur2010]&lt;/p&gt;
&lt;h2 id=&#34;ejercicios&#34;&gt;Ejercicios&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;¿Existe relación entre las emisiones de CO&lt;!-- raw HTML omitted --&gt;2&lt;!-- raw HTML omitted --&gt; y el PIB? Ajuste un modelo de regresión lineal para la evaluar dicha relación siguiendo la serie de pasos desarrollados en esta sección.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;La instalación básica de R trae integradas algunas tablas de datos, entre las que se encuentra &lt;code&gt;airquality&lt;/code&gt;. Dicha tabla contiene información de cinco variables ambientales medidas en la ciudad de Nueva York. El objetivo original era probar como varía la concentración de ozono en el aire (gas contaminante cuando se presenta a nivel del suelo) en relación a las condiciones de radiación solar, velocidad del viento y la temperatura. Ajuste un modelo de regresión lineal simple a la relación entre ozono y velocidad del viento. ¡Es este un modelo adecuado? ¿Cómo se podría mejorar el modelo?&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;bibliografía&#34;&gt;Bibliografía&lt;/h1&gt;
</description>
    </item>
    
    <item>
      <title>Ajuste modelos no lineales</title>
      <link>/recursos/ajuste-modelos-no-lineales/</link>
      <pubDate>Fri, 10 Jan 2020 16:00:00 +0000</pubDate>
      
      <guid>/recursos/ajuste-modelos-no-lineales/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Análisis multivariado</title>
      <link>/recursos/analisis-multivariado/</link>
      <pubDate>Thu, 10 Jan 2019 16:00:00 +0000</pubDate>
      
      <guid>/recursos/analisis-multivariado/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Diagnóstico de datos</title>
      <link>/recursos/diagnostico-de-datos/</link>
      <pubDate>Thu, 10 Jan 2019 16:00:00 +0000</pubDate>
      
      <guid>/recursos/diagnostico-de-datos/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
